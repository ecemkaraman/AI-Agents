### **Note on the Course -> Framework-Agnostic**

- **Focus on Concepts:** The course avoids framework dependencies, enabling students to apply concepts across various projects.
- **Implementation Approach:** Uses a dummy agent library and a simple serverless API (Hugging Face’s Serverless API) for accessibility.
- **Dummy agent library:** Not for prod use but good for learning how AI Agents work
- **Jupyter Notebook:** https://huggingface.co/agents-course/notebooks/blob/main/dummy_agent_library.ipynb

---

### **Hugging Face Serverless API**

- **Purpose:** Provides model inference without installation or deployment.
- **Usage Example:** Calls the Llama-3.2-3B-Instruct model for text generation.

```python
import os
from huggingface_hub import InferenceClient

os.environ["HF_TOKEN"]="hf_xxxxxxxxxxxxxx"
client = InferenceClient("meta-llama/Llama-3.2-3B-Instruct")

output = client.text_generation(
    "The capital of France is",
    max_new_tokens=100,
)

print(output)
```

- **Ensuring Correct Model Output:** Applying the correct chat template ensures expected behavior.

```python
prompt="""<|begin_of_text|><|start_header_id|>user<|end_header_id|>
The capital of France is<|eot_id|><|start_header_id|>assistant<|end_header_id|>"""
output = client.text_generation(prompt, max_new_tokens=100)
```

- **Recommended Approach:** Use `chat.completions.create()` for structured interactions across different models.

---

### **Building a Dummy AI Agent**

### **System Prompt: Defining Agent Behavior**

- Specifies available **tools** and **Thought → Action → Observation (TAO) cycle**.
- Example Tool: `get_weather` to fetch current weather data.

```
Answer the following questions as best you can. You have access to the following tools:

get_weather: Get the current weather in a given location.

Use the following format:
Thought: I need to check the current weather.
Action:
{
  "action": "get_weather",
  "action_input": {"location": "New York"}
}
Observation: [Function Response]
```

---

### **Manually Applying Prompts**

- **Basic Prompt Formatting (Direct Approach)**

```python
prompt=f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>
{SYSTEM_PROMPT}
<|eot_id|><|start_header_id|>user<|end_header_id|>
What's the weather in London?
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
"""
```

- **Using the Chat Template for Structuring Messages**

```python
messages=[
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": "What's the weather in London?"}
]
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-3.2-3B-Instruct")
tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
```

---

### **Handling Tool Execution**

### **Issue: Model Hallucination**

- Without execution control, the model may hallucinate results.

```
Observation: The current weather in London is mostly cloudy with a high of 12°C.
```

### **Solution: Stop and Parse**

- **Stopping at Observation prevents fake tool responses.**

```python
output = client.text_generation(prompt, max_new_tokens=200, stop=["Observation:"])
```

- **Now, execute the actual function:**

```python
def get_weather(location):
    return f"The weather in {location} is sunny with low temperatures.\\n"

get_weather('London')
```

- **Appending Function Output & Resuming Generation**

```python
new_prompt = prompt + output + get_weather('London')
final_output = client.text_generation(new_prompt, max_new_tokens=200)
```

---

### **Final Output**

```
Final Answer: The weather in London is sunny with low temperatures.
```

---

### **Key Learnings**

1. **Creating AI Agents from Scratch**: Defined system prompts, tools, and execution flow.
2. **Challenges & Manual Steps**: Managing hallucinations, tool execution, and structured outputs.
3. **The Need for Agent Libraries**: Tools like `smolagents` streamline agent development, reducing manual effort.
