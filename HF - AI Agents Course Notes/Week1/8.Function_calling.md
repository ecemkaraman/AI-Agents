## **ğŸ”¹ Fine-Tuning an LLM for Function Calling**

Fine-tuning a **Large Language Model (LLM)** for function calling enhances its ability to take **actions** and interpret **observations** during the training phase. This approach moves beyond prompt-based methods, making AI models **more robust and effective** in real-world applications.

- Recommended prerequisites:
    - **Fine-Tune an LLM** with **Transformers**
    - **Use SFTTrainer** for fine-tuning (Check Hugging Faceâ€™s documentation)

---

## **ğŸ¯ What Youâ€™ll Learn**

1. **Function Calling**: How LLMs use structured conversations to trigger tools dynamically.
2. **LoRA (Low-Rank Adaptation)**: A lightweight fine-tuning method that reduces computation/storage needs.
3. **Thought â†’ Act â†’ Observe Cycle**: A framework to **structure** model actions and track intermediate steps.
4. **Special Tokens for Function Calling**:
    - **[AVAILABLE_TOOLS]** â†’ Start of available tool list
    - **[/AVAILABLE_TOOLS]** â†’ End of tool list
    - **[TOOL_CALLS]** â†’ Action execution
    - **[TOOL_RESULTS]** â†’ Observations from external tools
    - **[/TOOL_RESULTS]** â†’ End of the observation phase

---

## **ğŸ¤– What is Function Calling?**

ğŸ”¹ **Function Calling** enables an LLM to **take actions** in its environment, unlike standard chat models that simply generate responses.

ğŸ”¹ Introduced in **GPT-4**, later adopted by models like **Mistral**.

ğŸ”¹ Similar to **Agent Tools**, but instead of relying on external functions, the **model itself** learns to **invoke tools dynamically**.

---

## **ğŸ› ï¸ How Function Calling Works**

A function-calling model follows a **three-step cycle**:

1. **Think** ğŸ¤” â€“ "What action do I need to take?"
2. **Act** ğŸš€ â€“ "Format the action properly and execute it."
3. **Observe** ğŸ‘€ â€“ "Analyze the response and take further action."

ğŸ”¹ Example with **Mistral API**:

```json
[
  {"role": "user", "content": "What's the status of my transaction T1001?"},
  {"role": "assistant", "function_call": {"name": "retrieve_payment_status", "arguments": "{\\"transaction_id\\": \\"T1001\\"}"}},
  {"role": "tool", "name": "retrieve_payment_status", "content": "{\\"status\\": \\"Paid\\"}"},
  {"role": "assistant", "content": "Your transaction T1001 has been successfully paid."}
]

```

---

## **ğŸ› ï¸ Fine-Tuning an LLM for Function Calling**

**ğŸ”¹ Steps in Model Training:**

1. **Pre-training**: The model is trained on large datasets (e.g., `google/gemma-2-2b`).
2. **Fine-tuning for Instruction Following**: A refined model is trained to follow structured instructions (`google/gemma-2-2b-it`).
3. **Alignment**: The model is aligned to preferences (e.g., politeness for customer service).

**ğŸ”¹ Why Fine-Tune `gemma-2-2b-it` Instead of `gemma-2-2b`?**

- The instruction-tuned version **already** follows structured responses.
- Saves time by **minimizing the data needed for function calling training**.

---

## **ğŸ› ï¸ LoRA (Low-Rank Adaptation)**

### **ğŸ’¡ Why Use LoRA for Fine-Tuning?**

âœ… **Efficient Training** â€“ Reduces **trainable parameters** and computational costs.

âœ… **Memory-Efficient** â€“ No need to modify the entire model.

âœ… **Lightweight Adaptation** â€“ LoRA adapters **can be merged** with the base model for inference, avoiding latency issues.

### **ğŸ› ï¸ How LoRA Works?**

ğŸ”¹ Instead of updating **all weights**, LoRA **injects adapters** into Transformer layers.

ğŸ”¹ During training:

- The **base model is frozen**.
- Only the **LoRA adapters are trained**.
- The model **learns function-calling behavior efficiently**.

ğŸ”¹ During inference:

- The **adapter weights are merged** with the model.
- No extra computational overhead is required.

---

## **ğŸš€ Summary**

âœ… **Fine-Tuning for Function Calling** enables LLMs to execute actions dynamically.

âœ… **LoRA** makes fine-tuning **faster, cheaper, and scalable**.

âœ… **Special Tokens & Thought â†’ Act â†’ Observe Cycle** improve structured tool interactions.

âœ… Function-calling models enhance **agentic AI systems** by seamlessly integrating **external tool execution** into model workflows.

ğŸš€ **Next Step:** Train a function-calling model using **LoRA & SFTTrainer**! ğŸ”¥
