## **🔹 Fine-Tuning an LLM for Function Calling**

Fine-tuning a **Large Language Model (LLM)** for function calling enhances its ability to take **actions** and interpret **observations** during the training phase. This approach moves beyond prompt-based methods, making AI models **more robust and effective** in real-world applications.

- Recommended prerequisites:
    - **Fine-Tune an LLM** with **Transformers**
    - **Use SFTTrainer** for fine-tuning (Check Hugging Face’s documentation)

---

## **🎯 What You’ll Learn**

1. **Function Calling**: How LLMs use structured conversations to trigger tools dynamically.
2. **LoRA (Low-Rank Adaptation)**: A lightweight fine-tuning method that reduces computation/storage needs.
3. **Thought → Act → Observe Cycle**: A framework to **structure** model actions and track intermediate steps.
4. **Special Tokens for Function Calling**:
    - **[AVAILABLE_TOOLS]** → Start of available tool list
    - **[/AVAILABLE_TOOLS]** → End of tool list
    - **[TOOL_CALLS]** → Action execution
    - **[TOOL_RESULTS]** → Observations from external tools
    - **[/TOOL_RESULTS]** → End of the observation phase

---

## **🤖 What is Function Calling?**

🔹 **Function Calling** enables an LLM to **take actions** in its environment, unlike standard chat models that simply generate responses.

🔹 Introduced in **GPT-4**, later adopted by models like **Mistral**.

🔹 Similar to **Agent Tools**, but instead of relying on external functions, the **model itself** learns to **invoke tools dynamically**.

---

## **🛠️ How Function Calling Works**

A function-calling model follows a **three-step cycle**:

1. **Think** 🤔 – "What action do I need to take?"
2. **Act** 🚀 – "Format the action properly and execute it."
3. **Observe** 👀 – "Analyze the response and take further action."

🔹 Example with **Mistral API**:

```json
[
  {"role": "user", "content": "What's the status of my transaction T1001?"},
  {"role": "assistant", "function_call": {"name": "retrieve_payment_status", "arguments": "{\\"transaction_id\\": \\"T1001\\"}"}},
  {"role": "tool", "name": "retrieve_payment_status", "content": "{\\"status\\": \\"Paid\\"}"},
  {"role": "assistant", "content": "Your transaction T1001 has been successfully paid."}
]

```

---

## **🛠️ Fine-Tuning an LLM for Function Calling**

**🔹 Steps in Model Training:**

1. **Pre-training**: The model is trained on large datasets (e.g., `google/gemma-2-2b`).
2. **Fine-tuning for Instruction Following**: A refined model is trained to follow structured instructions (`google/gemma-2-2b-it`).
3. **Alignment**: The model is aligned to preferences (e.g., politeness for customer service).

**🔹 Why Fine-Tune `gemma-2-2b-it` Instead of `gemma-2-2b`?**

- The instruction-tuned version **already** follows structured responses.
- Saves time by **minimizing the data needed for function calling training**.

---

## **🛠️ LoRA (Low-Rank Adaptation)**

### **💡 Why Use LoRA for Fine-Tuning?**

✅ **Efficient Training** – Reduces **trainable parameters** and computational costs.

✅ **Memory-Efficient** – No need to modify the entire model.

✅ **Lightweight Adaptation** – LoRA adapters **can be merged** with the base model for inference, avoiding latency issues.

### **🛠️ How LoRA Works?**

🔹 Instead of updating **all weights**, LoRA **injects adapters** into Transformer layers.

🔹 During training:

- The **base model is frozen**.
- Only the **LoRA adapters are trained**.
- The model **learns function-calling behavior efficiently**.

🔹 During inference:

- The **adapter weights are merged** with the model.
- No extra computational overhead is required.

---

## **🚀 Summary**

✅ **Fine-Tuning for Function Calling** enables LLMs to execute actions dynamically.

✅ **LoRA** makes fine-tuning **faster, cheaper, and scalable**.

✅ **Special Tokens & Thought → Act → Observe Cycle** improve structured tool interactions.

✅ Function-calling models enhance **agentic AI systems** by seamlessly integrating **external tool execution** into model workflows.

🚀 **Next Step:** Train a function-calling model using **LoRA & SFTTrainer**! 🔥
