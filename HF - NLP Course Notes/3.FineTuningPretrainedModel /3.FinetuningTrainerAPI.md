### **ğŸ“Œ Fine-Tuning a Model Using the Trainer API**

---

## **1ï¸âƒ£ Overview: Why Use the Trainer API?**

The **ğŸ¤— Trainer API** simplifies **fine-tuning pretrained Transformer models** by handling:

âœ” **Training loops** (gradient updates, optimizer, scheduler).

âœ” **Evaluation & Metrics Calculation** (accuracy, F1, etc.).

âœ” **Batching & Dynamic Padding** (via `DataCollatorWithPadding`).

âœ” **Saving & Logging** (model checkpoints, logs).

ğŸš€ **Goal:** Fine-tune **BERT (`bert-base-uncased`)** on the **MRPC (Microsoft Research Paraphrase Corpus)** dataset.

---

## **2ï¸âƒ£ Setting Up the Dataset & Tokenizer**

ğŸ’¡ **Load and Preprocess Dataset**

```python
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

# Load dataset from Hugging Face Hub
raw_datasets = load_dataset("glue", "mrpc")

# Load tokenizer
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Tokenization function
def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)

# Tokenize the dataset
tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)

# Define data collator for dynamic padding
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

```

âœ” **Efficiently tokenizes & batches data**

âœ” **Ensures each batch is padded dynamically**

---

## **3ï¸âƒ£ Defining Training Arguments**

ğŸ’¡ **Set up `TrainingArguments` to control fine-tuning parameters.**

âœ… **Initialize Training Arguments**

```python
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="test-trainer",  # Where to save model checkpoints
    evaluation_strategy="epoch",  # Evaluate at the end of each epoch
    save_strategy="epoch",  # Save checkpoint at each epoch
    per_device_train_batch_size=8,  # Batch size for training
    per_device_eval_batch_size=8,  # Batch size for evaluation
    num_train_epochs=3,  # Number of training epochs
    weight_decay=0.01,  # L2 regularization
    logging_dir="logs",  # Where to store logs
    push_to_hub=False,  # Set True if you want to push model to Hugging Face Hub
)

```

âœ” **Defines training hyperparameters**

âœ” **Enables evaluation & checkpoint saving per epoch**

---

## **4ï¸âƒ£ Initializing the Model**

ğŸ’¡ **Load a Pretrained Model for Sequence Classification (BERT).**

âœ… **Load Model & Define Labels**

```python
from transformers import AutoModelForSequenceClassification

# Load BERT model for binary classification (2 labels)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

```

âœ” **Automatically adapts model for binary classification**

âœ” **Replaces pretraining head with a new classification head**

âš ï¸ **Warning:** A new classification layer is randomly initialized. The model will issue a warning that:

- The **pretraining head is discarded**
- **New classification layers are randomly initialized**
- **Fine-tuning is required!**

---

## **5ï¸âƒ£ Setting Up the Trainer**

ğŸ’¡ **The `Trainer` API handles training, evaluation, logging, and saving automatically.**

âœ… **Initialize Trainer**

```python
from transformers import Trainer

trainer = Trainer(
    model=model,  # Model to train
    args=training_args,  # Training arguments
    train_dataset=tokenized_datasets["train"],  # Training data
    eval_dataset=tokenized_datasets["validation"],  # Validation data
    data_collator=data_collator,  # Handles dynamic padding
    tokenizer=tokenizer,  # Tokenizer used for preprocessing
)

```

âœ” **Automatically batches and tokenizes data**

âœ” **Handles GPU/TPU acceleration & mixed precision**

---

## **6ï¸âƒ£ Fine-Tuning the Model**

âœ… **Start Training**

```python
trainer.train()

```

âœ” **Trains model using gradient updates & optimizer**

âœ” **Logs training loss every 500 steps**

âœ” **Saves checkpoints at the end of each epoch**

âš ï¸ **By default, training only logs loss.**

To track **accuracy & F1 score**, we need **evaluation metrics**.

---

## **7ï¸âƒ£ Adding Custom Evaluation Metrics**

ğŸ’¡ **Define `compute_metrics()` function to evaluate performance.**

âœ… **Load Evaluation Metric (Accuracy & F1 Score)**

```python
import evaluate
import numpy as np

# Load GLUE benchmark metrics for MRPC dataset
metric = evaluate.load("glue", "mrpc")

# Define function to compute accuracy & F1
def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)  # Get highest probability class
    return metric.compute(predictions=predictions, references=labels)

```

âœ” **Extracts predictions from logits**

âœ” **Computes accuracy & F1 score**

âœ… **Test Metrics on Validation Set**

```python
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)

# Compute accuracy & F1
print(compute_metrics((predictions.predictions, predictions.label_ids)))

```

âœ” **Computes evaluation metrics before integrating them into `Trainer`**

---

## **8ï¸âƒ£ Training with Automatic Evaluation**

ğŸ’¡ **Modify Trainer to evaluate after each epoch.**

âœ… **Reinitialize `Trainer` with `compute_metrics()`**

```python
training_args = TrainingArguments(
    output_dir="test-trainer",
    evaluation_strategy="epoch",  # Evaluate at the end of each epoch
    save_strategy="epoch",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="logs",
)

# Load a new model to retrain from scratch
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,  # Compute Accuracy & F1
)

# Start fine-tuning with evaluation after each epoch
trainer.train()

```

âœ” **Automatically evaluates after each epoch**

âœ” **Tracks accuracy & F1 score in logs**

---

## **9ï¸âƒ£ Checking Model Performance**

ğŸ’¡ **After training, check validation accuracy & F1 score.**

âœ… **Evaluate Final Model**

```python
final_results = trainer.evaluate()
print(final_results)

```

âœ” **Reports final accuracy & F1 score on validation set**

âœ… **Example Output (May Vary Slightly Due to Random Initialization)**

```python
{'eval_loss': 0.312,
 'eval_accuracy': 0.8578,
 'eval_f1': 0.8996,
 'epoch': 3.0}

```

âœ” **Final model achieves ~85.78% accuracy & 89.96% F1-score**

ğŸ“Œ **Compare with BERT Paper:**

- The BERT Base model reported **88.9 F1-score**
- Our model achieves **comparable performance (~89.96 F1)** ğŸ¯

---

## **ğŸ”Ÿ Next Steps & Optimization**

ğŸ’¡ **Boost performance using additional Trainer settings:**

âœ… **Enable `fp16` for Mixed Precision Training (Faster & More Efficient)**

```python
training_args = TrainingArguments(
    output_dir="test-trainer",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=4,  # Increase epochs
    weight_decay=0.01,
    logging_dir="logs",
    fp16=True,  # Use Mixed Precision Training
)

```

âœ… **Use Multi-GPU or TPU for Faster Training**

```python
import torch
torch.cuda.is_available()  # Check if GPU is available

```

âœ” **Trainer automatically scales across multiple GPUs/TPUs**

âœ… **Push Model to the Hugging Face Hub**

```python
trainer.push_to_hub()

```

âœ” **Uploads trained model to Hugging Face Model Hub**

---

## **ğŸ¯ Summary â€“ Key Takeaways**

âœ” **Trainer API simplifies fine-tuning** â†’ Handles batching, padding, optimizer, logging.

âœ” **Evaluation metrics (Accuracy & F1) are added via `compute_metrics()`**.

âœ” **Model achieves ~85.78% accuracy & 89.96% F1 on MRPC**.

âœ” **Trainer supports GPU/TPU acceleration & mixed precision (`fp16`).**

âœ” **Model can be pushed to Hugging Face Hub for public use!** ğŸš€

---

ğŸ”¥ **Next:** Fine-tuning in **pure PyTorch** without the Trainer API! ğŸš€
