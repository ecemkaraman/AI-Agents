### **ğŸ“Œ Sharing Models & Tokenizers on the Hugging Face Hub**

---

## **1ï¸âƒ£ Overview: What is the Hugging Face Hub?**

The **Hugging Face Hub** ([**huggingface.co**](https://huggingface.co/)) is a **centralized platform** where:

âœ” **State-of-the-art ML models** are **shared, used, and versioned**.

âœ” **Over 10,000+ models** are available **for NLP, vision, and audio** tasks.

âœ” **Public models are free** (Private models require a paid plan).

âœ” **Every model gets an automatic hosted **Inference API**.

ğŸš€ **Goal:** Learn how to:

ğŸ”¹ Upload a model to the Hugging Face Hub.

ğŸ”¹ Share & version models with Git-like repositories.

ğŸ”¹ Use & download models from the Hub.

---

## **2ï¸âƒ£ Setting Up a Hugging Face Account**

ğŸ’¡ **To upload models, you need a Hugging Face account.**

âœ… **Sign up on the Hugging Face Hub**

1. Go to [**huggingface.co/join**](https://huggingface.co/join).
2. Create an account (or log in if you already have one).
3. Generate an authentication token:
    - Navigate to **Settings â†’ Access Tokens**.
    - Click **New Token**, set permissions to **Write**, and copy it.

âœ… **Log in via CLI**

```python
from huggingface_hub import notebook_login

notebook_login()

```

âœ” **Prompts you to paste your token**.

âœ” **Grants access to upload models & datasets**.

âœ… **Check Authentication**

```python
!huggingface-cli whoami

```

âœ” **Verifies your connection to the Hugging Face Hub**.

---

## **3ï¸âƒ£ Uploading a Model to the Hub**

ğŸ’¡ **Use `push_to_hub()` to upload models, tokenizers, and configs.**

âœ… **Load & Fine-Tune a Model**

```python
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
from datasets import load_dataset
import torch

# Load dataset
dataset = load_dataset("glue", "mrpc")

# Load model
model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=2)

# Define training arguments
training_args = TrainingArguments(
    output_dir="bert-mrpc", push_to_hub=True, evaluation_strategy="epoch"
)

# Trainer
trainer = Trainer(model=model, args=training_args, train_dataset=dataset["train"])

```

âœ” **Prepares model for training & Hub upload**

âœ… **Push Model to the Hub**

```python
trainer.push_to_hub()

```

âœ” **Automatically uploads model, tokenizer, and logs**

âœ” **Creates a public repository at `huggingface.co/{username}/bert-mrpc`**

âœ… **Manually Upload a Model**

```python
model.push_to_hub("bert-mrpc")

```

âœ” **Uploads model separately from training artifacts**

âœ… **Upload Tokenizer**

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
tokenizer.push_to_hub("bert-mrpc")

```

âœ” **Uploads tokenizer configuration**

---

## **4ï¸âƒ£ Using a Model from the Hub**

ğŸ’¡ **Once uploaded, models can be loaded directly from the Hub!**

âœ… **Load the Model from the Hub**

```python
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("username/bert-mrpc")

```

âœ” **Downloads the model & weights automatically**

âœ… **Load the Tokenizer**

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("username/bert-mrpc")

```

âœ” **Ensures compatibility with model architecture**

âœ… **Use Model for Inference**

```python
import torch

inputs = tokenizer("Hugging Face is awesome!", return_tensors="pt")
outputs = model(**inputs)

logits = outputs.logits
predicted_class = torch.argmax(logits, dim=-1).item()
print(f"Predicted class: {predicted_class}")

```

âœ” **Runs inference using the fine-tuned model**

---

## **5ï¸âƒ£ Managing Model Versions with Git**

ğŸ’¡ **Hugging Face models are stored as Git repositories.**

âœ… **Clone Your Model Repository**

```bash
git clone <https://huggingface.co/username/bert-mrpc>
cd bert-mrpc

```

âœ” **Creates a local copy of the repo**

âœ… **Update & Push Changes**

```bash
git add .
git commit -m "Updated model"
git push

```

âœ” **Syncs changes to the Hub**

âœ… **Track Model Versions**

```bash
git log

```

âœ” **Shows model version history**

---

## **6ï¸âƒ£ Uploading Checkpoints & Logs**

ğŸ’¡ **Use `trainer.save_model()` to save & version intermediate checkpoints.**

âœ… **Save Checkpoint Locally**

```python
trainer.save_model("checkpoint-1000")

```

âœ” **Stores model weights at step 1000**

âœ… **Push Checkpoint to Hub**

```python
!huggingface-cli upload bert-mrpc checkpoint-1000

```

âœ” **Makes checkpoint accessible on the Hub**

âœ… **Load Checkpoint Later**

```python
model = AutoModelForSequenceClassification.from_pretrained("username/bert-mrpc/checkpoint-1000")

```

âœ” **Resumes training or runs inference on a specific checkpoint**

---

## **7ï¸âƒ£ Running Model Inference via the Hub API**

ğŸ’¡ **The Hub provides an online Inference API for public models.**

âœ… **Run API Inference**

```python
import requests

API_URL = "<https://api-inference.huggingface.co/models/username/bert-mrpc>"
headers = {"Authorization": "Bearer YOUR_HUGGINGFACE_TOKEN"}

data = {"inputs": "Hugging Face makes AI easy!"}
response = requests.post(API_URL, headers=headers, json=data)
print(response.json())

```

âœ” **Runs inference without downloading the model**

âœ… **Check Inference API on the Model Page**

1ï¸âƒ£ **Go to `huggingface.co/{username}/bert-mrpc`**

2ï¸âƒ£ **Enter text into the widget**

3ï¸âƒ£ **See real-time predictions!** ğŸ¯

---

## **8ï¸âƒ£ Deleting & Managing Models**

ğŸ’¡ **Manage models via CLI or web interface.**

âœ… **List Your Models**

```bash
huggingface-cli models

```

âœ” **Shows all models in your account**

âœ… **Delete a Model**

```bash
huggingface-cli delete bert-mrpc

```

âœ” **Removes model from Hub**

âœ… **Delete via Web Interface**

1ï¸âƒ£ **Go to `huggingface.co/models`**

2ï¸âƒ£ **Click on your model**

3ï¸âƒ£ **Settings â†’ Delete**

---

## **ğŸ¯ Summary â€“ Key Takeaways**

âœ” **Hugging Face Hub is a centralized repository for ML models**

âœ” **Models, tokenizers, and logs can be uploaded via `push_to_hub()`**

âœ” **Public models get an Inference API for free**

âœ” **Versioning works via Git & CLI tools**

âœ” **You can use models directly from the Hub with `from_pretrained()`**